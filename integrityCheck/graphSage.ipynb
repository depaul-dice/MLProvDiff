{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "- Check graphSage works by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Feb__8_05:53:42_Coordinated_Universal_Time_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.66\n",
      "Build cuda_12.1.r12.1/compiler.32415258_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.0+cu121.html\n",
      "Collecting torch-scatter\n",
      "  Using cached torch_scatter-2.1.1.tar.gz (107 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py): started\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): finished with status 'done'\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.1.1-cp311-cp311-win_amd64.whl size=500932 sha256=57883e7469ec64d979d73f28374bf49eb5909f0e3f17d02ac1cbab83fd4457fb\n",
      "  Stored in directory: c:\\users\\mnihy\\appdata\\local\\pip\\cache\\wheels\\e1\\45\\de\\7e6c2b34bf0c92ea931392eb9930fa25ac12bf455e68ae1d6e\n",
      "Successfully built torch-scatter\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.1\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.0+cu121.html\n",
      "Collecting torch-sparse\n",
      "  Using cached torch_sparse-0.6.17.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scipy in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch-sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from scipy->torch-sparse) (1.24.3)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py): started\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): finished with status 'done'\n",
      "  Created wheel for torch-sparse: filename=torch_sparse-0.6.17-cp311-cp311-win_amd64.whl size=1178379 sha256=32bb0ccde3ebbf8ce0901256d1bc79359fde01a875ea17d8cbee17e557d01b3f\n",
      "  Stored in directory: c:\\users\\mnihy\\appdata\\local\\pip\\cache\\wheels\\43\\27\\bc\\21943b121fafafd76c514e5f34c8ad8592766bee55f6771b43\n",
      "Successfully built torch-sparse\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.17\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch-geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch-geometric) (2.28.2)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch-geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from jinja2->torch-geometric) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->torch-geometric) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->torch-geometric) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mnihy\\anaconda3\\envs\\practicum\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.0.0+cu121.html\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.0.0+cu121.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx# read the pickled data from generateData folder\n",
    "import pickle\n",
    "\n",
    "adjacencyList = pickle.load(open(\"../generateData/adjacencyList.pkl\", \"rb\"))x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 0,  2],\n",
       "        [ 0,  3],\n",
       "        [ 0,  4],\n",
       "        [ 1,  5],\n",
       "        [ 1,  6],\n",
       "        [ 1,  7],\n",
       "        [ 1,  8],\n",
       "        [ 2,  9],\n",
       "        [ 2, 10],\n",
       "        [ 2, 11],\n",
       "        [ 2, 12],\n",
       "        [ 3, 13],\n",
       "        [ 3, 14],\n",
       "        [ 3, 15],\n",
       "        [ 3, 16],\n",
       "        [ 4, 17],\n",
       "        [ 4, 18],\n",
       "        [ 4, 19],\n",
       "        [ 4, 20]], dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacencyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 1.8202, Test Acc: 0.4770\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mnihy\\OneDrive - The University of Chicago\\uchicago\\23 spring\\practicum\\MLProvDiff\\integrityCheck\\graphSage.ipynb Cell 7\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m loss \u001b[39m=\u001b[39m train()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     acc \u001b[39m=\u001b[39m test()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Test Acc: \u001b[39m\u001b[39m{\u001b[39;00macc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\mnihy\\OneDrive - The University of Chicago\\uchicago\\23 spring\\practicum\\MLProvDiff\\integrityCheck\\graphSage.ipynb Cell 7\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     pred \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     correct \u001b[39m=\u001b[39m pred[data\u001b[39m.\u001b[39mtest_mask]\u001b[39m.\u001b[39meq(data\u001b[39m.\u001b[39my[data\u001b[39m.\u001b[39mtest_mask])\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\mnihy\\OneDrive - The University of Chicago\\uchicago\\23 spring\\practicum\\MLProvDiff\\integrityCheck\\graphSage.ipynb Cell 7\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mnihy/OneDrive%20-%20The%20University%20of%20Chicago/uchicago/23%20spring/practicum/MLProvDiff/integrityCheck/graphSage.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m    128\u001b[0m     x \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mrelu(), x[\u001b[39m1\u001b[39m])\n\u001b[0;32m    130\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, size\u001b[39m=\u001b[39;49msize)\n\u001b[0;32m    132\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_l(out)\n\u001b[0;32m    134\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:484\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    482\u001b[0m         aggr_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[1;32m--> 484\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate(out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39maggr_kwargs)\n\u001b[0;32m    486\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    487\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:608\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[1;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[0;32m    596\u001b[0m               ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m               dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    598\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[39m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggr_module(inputs, index, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[0;32m    609\u001b[0m                             dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim)\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:109\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[1;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dim_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    108\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(x, index, ptr, dim_size, dim, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    110\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\aggr\\basic.py:34\u001b[0m, in \u001b[0;36mMeanAggregation.forward\u001b[1;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m             ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m             dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 34\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce(x, index, ptr, dim_size, dim, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:155\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[1;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[39mreturn\u001b[39;00m segment(x, ptr, reduce\u001b[39m=\u001b[39mreduce)\n\u001b[0;32m    154\u001b[0m \u001b[39massert\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m \u001b[39mreturn\u001b[39;00m scatter(x, index, dim, dim_size, reduce)\n",
      "File \u001b[1;32mc:\\Users\\mnihy\\anaconda3\\lib\\site-packages\\torch_geometric\\utils\\scatter.py:82\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[0;32m     79\u001b[0m     count \u001b[39m=\u001b[39m count\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     81\u001b[0m     index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n\u001b[1;32m---> 82\u001b[0m     out \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39;49mnew_zeros(size)\u001b[39m.\u001b[39;49mscatter_add_(dim, index, src)\n\u001b[0;32m     84\u001b[0m     \u001b[39mreturn\u001b[39;00m out \u001b[39m/\u001b[39m broadcast(count, out, dim)\n\u001b[0;32m     86\u001b[0m \u001b[39m# For \"min\" and \"max\" reduction, we prefer `scatter_reduce_` on CPU or\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m# in case the input does not require gradients:\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Load the Cora dataset and apply normalization transform\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphSAGE(dataset.num_features, 16, dataset.num_classes).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "    return correct / data.test_mask.sum().item()\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        acc = test()\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the pickled data from generateData folder\n",
    "import pickle\n",
    "\n",
    "adjacencyList = pickle.load(open(\"../generateData/adjacencyList.pkl\", \"rb\"))\n",
    "nodeLabels = pickle.load(open(\"../generateData/nodeLabels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.x is feature matrix. Use nodeLabes instead\n",
    "# data.edge_index is edge list. Use adjacencyList instead\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(data.x, data.edge_index)\n",
    "pred = out.argmax(dim=1)\n",
    "# check the unique values in pred\n",
    "pred.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
